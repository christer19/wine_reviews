{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Class that i made which normalizes texts\n",
    "from text_normalization import TextNormalization\n",
    "\n",
    "random_state = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_parquet('wine_reviews.parq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_description(x):\n",
    "    # Some descriptions are only 'Imported by Someone', thouse descriptions are invalid\n",
    "    if 'imported by' in x.lower():\n",
    "        return False\n",
    "    # Short descriptions are also cutted of the recommended section\n",
    "    elif len(x)<50:\n",
    "        return False\n",
    "    else:\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emininating short descriptions and the invalid ones\n",
    "df['valid_description'] = df.description.apply(lambda x: valid_description(x))\n",
    "print('Eliminating {} invalid descriptions'.format(len(df[~df['valid_description']])))\n",
    "df = df[df['valid_description']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizes the text\n",
    "text_normalization = TextNormalization()\n",
    "df['text'] = df['description'].apply(lambda x: text_normalization.text_normalization(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding variety to text if that exists\n",
    "df['text'] = df.apply(lambda x: x.text + ' ' + x.variety if x.variety is not None else x.text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "MAX_FEATURES = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(max_features=MAX_FEATURES)\n",
    "dtm = tf.fit_transform(df['text'].values.astype('U'))\n",
    "dtm = pd.DataFrame(dtm.todense(), columns=tf.get_feature_names())\n",
    "\n",
    "df_with_features = dtm.merge(df, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df), len(dtm), len(df_with_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the best features(words)  to train \n",
    "We are considering 3 features:\n",
    "* Number of different important variety that this word appears. (A variety is important if it has more than 5 titles)\n",
    "* Number of different titles where this word appears\n",
    "\n",
    "We believe that if this word appers in different kinds of wind it is not able to distinguish well the titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "dict_column_n_variety = {}\n",
    "for column in tqdm(sorted(dtm.columns)):\n",
    "    try:\n",
    "        mask = (df_with_features[column]>0)\n",
    "        n_important_variety = len(\n",
    "            [i for i in df_with_features[mask].variety.value_counts() if i>5]\n",
    "        )\n",
    "        n_titles = df_with_features[mask].title.nunique()\n",
    "#         sum_column = int(df_with_features[column].sum())\n",
    "        dict_column_n_variety[column] = {\n",
    "            'n_important_variety': n_important_variety,\n",
    "            'n_titles': n_titles,\n",
    "#             'sum_column':sum_column\n",
    "        }\n",
    "    except Exception as exp:\n",
    "        print(exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['n_important_variety', 'n_titles']\n",
    "\n",
    "df_features_variety = pd.DataFrame(dict_column_n_variety).T\n",
    "\n",
    "X = df_features_variety.values\n",
    "words_labels = list(df_features_variety.index)\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "df_normalized = pd.DataFrame(X_normalized)\n",
    "df_normalized.columns = feature_columns\n",
    "df_normalized['word'] = words_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df_normalized, x='n_important_variety',y='n_titles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering the words by those features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3, random_state=0).fit(df_normalized[feature_columns])\n",
    "df_normalized['label'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(df_normalized, x='n_important_variety',y='n_titles', color='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_normalized.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering the words that are probably less able to distinguish the wines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_eliminate = sorted(df_normalized[df_normalized['label']!=0].word.unique())\n",
    "words_to_keep = sorted(df_normalized[df_normalized['label']==0].word.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_filtered = dtm.drop(columns=words_to_eliminate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dtm_filtered), len(df), len(dtm), len(df_with_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the recommedation system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NearestNeighbors(\n",
    "    n_neighbors=4, \n",
    "    algorithm='ball_tree',\n",
    "    n_jobs=-1\n",
    ")\n",
    "nn.fit(dtm_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_recommended = nn.kneighbors(dtm_filtered.values, return_distance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_recommendation = {}\n",
    "\n",
    "for original_index, list_of_index in tqdm(enumerate(index_recommended)):\n",
    "    text_list = []\n",
    "    try:\n",
    "        for index in list_of_index:\n",
    "            text_list.append(df.loc[index].title)\n",
    "        title = df.loc[original_index]['title']\n",
    "        dict_recommendation[title] = list(set(text_list)- set([title]))\n",
    "    except Exception as exp:\n",
    "        print(str(exp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('titles_recommended.json', 'w') as fp:\n",
    "    json.dump(dict_recommendation,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "for title, list_titles in dict_recommendation.items():\n",
    "    for i in list_titles:\n",
    "        new_list.append({\n",
    "            'title': title,\n",
    "            'recommended': i\n",
    "        })\n",
    "df_recommend = pd.DataFrame(new_list)\n",
    "df_recommend.to_parquet('titles_recommended.parq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
